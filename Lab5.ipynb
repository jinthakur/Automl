{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show azureml-contrib-fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade fairlearn==0.7.0 raiwidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print(\"Loading Data...\")\n",
    "data = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "features = ['PassengerId','Pclass','Sex','Age','SibSp','Parch', 'Fare', 'Embarked']\n",
    "X, y = data[features].values, data['Survived'].values\n",
    "\n",
    "S = data[['Age']].astype(int)\n",
    "S['Age'] = np.where(S.Age > 50, 'Over 50', '50 or younger')\n",
    "\n",
    "X_train, X_test, y_train, y_test, S_train, S_test = train_test_split(X, y, S, test_size=0.20, random_state=0, stratify=y)\n",
    "\n",
    "print(\"Training model...\")\n",
    "titanic_model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.metrics import selection_rate, MetricFrame\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "y_hat = titanic_model.predict(X_test)\n",
    "\n",
    "print(\"Overall Metrics:\")\n",
    "overall_selection_rate = selection_rate(y_test, y_hat)\n",
    "print(\"\\tSelection Rate:\", overall_selection_rate)\n",
    "overall_accuracy = accuracy_score(y_test, y_hat)\n",
    "print(\"\\tAccuracy:\", overall_accuracy)\n",
    "overall_recall = recall_score(y_test, y_hat)\n",
    "print(\"\\tRecall:\", overall_recall)\n",
    "overall_precision = precision_score(y_test, y_hat)\n",
    "print(\"\\tPrecision:\", overall_precision)\n",
    "\n",
    "print('\\nMetrics by Group:')\n",
    "metrics = {'selection_rate': selection_rate,\n",
    "           'accuracy': accuracy_score,\n",
    "           'recall': recall_score,\n",
    "           'precision': precision_score}\n",
    "\n",
    "group_metrics = MetricFrame(metrics=metrics,\n",
    "                             y_true=y_test,\n",
    "                             y_pred=y_hat,\n",
    "                             sensitive_features=S_test['Age'])\n",
    "\n",
    "print(group_metrics.by_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: go through the dasboard to understand the disparities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from raiwidgets import FairnessDashboard\n",
    "\n",
    "FairnessDashboard(sensitive_features=S_test,\n",
    "                   y_true=y_test,\n",
    "                   y_pred={\"titanic_model\": titanic_model.predict(X_test)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a5ee49a59f6686a8ecefdb44e4846997b259e3ed1c87b1258284d835f738ab3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
